{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BOS210.csv', sep =';', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "#    221004\nZ     47138\nName: 05, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['05'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "595858"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['05'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['time', '01', '03', '04', '05', '11', '12', '22', '24', '28', '31',\n       '32', '37', '38', '41', '011', '012', '013', '014', '031', '032', '033',\n       '034', '041', '042', '043', '044', '051', '052', '053', '054', '111',\n       '112', '113', '114', '121', '122', '123', '124', '221', '222', '223',\n       'K22', '241', 'K24', '281', 'K28', 'K311', 'K312321', 'K322', 'K371',\n       'K372381', 'K382', '411', '412', 'F055'],\n      dtype='object')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "|    137549\nName: 41, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['41'].value_counts()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                         time   01   03   04   05   11   12   22   24   28  \\\n0       02-11-2020 00:00:00.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n1       02-11-2020 00:00:00.1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n2       02-11-2020 00:00:00.2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n3       02-11-2020 00:00:00.3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n4       02-11-2020 00:00:00.4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n...                       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n863995  02-11-2020 23:59:59.5  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n863996  02-11-2020 23:59:59.6  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n863997  02-11-2020 23:59:59.7  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n863998  02-11-2020 23:59:59.8  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n863999  02-11-2020 23:59:59.9  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n\n        ...  K28 K311 K312321 K322 K371 K372381 K382  411  412 F055  \n0       ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n1       ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n2       ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n3       ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n4       ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n...     ...  ...  ...     ...  ...  ...     ...  ...  ...  ...  ...  \n863995  ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n863996  ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n863997  ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n863998  ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n863999  ...  NaN  NaN     NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN  \n\n[864000 rows x 56 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>01</th>\n      <th>03</th>\n      <th>04</th>\n      <th>05</th>\n      <th>11</th>\n      <th>12</th>\n      <th>22</th>\n      <th>24</th>\n      <th>28</th>\n      <th>...</th>\n      <th>K28</th>\n      <th>K311</th>\n      <th>K312321</th>\n      <th>K322</th>\n      <th>K371</th>\n      <th>K372381</th>\n      <th>K382</th>\n      <th>411</th>\n      <th>412</th>\n      <th>F055</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>02-11-2020 00:00:00.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>02-11-2020 00:00:00.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02-11-2020 00:00:00.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>02-11-2020 00:00:00.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>02-11-2020 00:00:00.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>863995</th>\n      <td>02-11-2020 23:59:59.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>863996</th>\n      <td>02-11-2020 23:59:59.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>863997</th>\n      <td>02-11-2020 23:59:59.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>863998</th>\n      <td>02-11-2020 23:59:59.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>863999</th>\n      <td>02-11-2020 23:59:59.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>864000 rows Ã— 56 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'F119'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mc:\\users\\emiel\\pycharmprojects\\simproj\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3361\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3362\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mc:\\users\\emiel\\pycharmprojects\\simproj\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:76\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mc:\\users\\emiel\\pycharmprojects\\simproj\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:108\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'F119'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mF119\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalue_counts()\n",
      "File \u001B[1;32mc:\\users\\emiel\\pycharmprojects\\simproj\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3458\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3457\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3458\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3459\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3460\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mc:\\users\\emiel\\pycharmprojects\\simproj\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3362\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3363\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3365\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_scalar(key) \u001B[38;5;129;01mand\u001B[39;00m isna(key) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhasnans:\n\u001B[0;32m   3366\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'F119'"
     ]
    }
   ],
   "source": [
    "df['F119'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('BOS211-7919015E-VT450903_2021-12-13_2021-12-13_SIGNAL_GROUP-unfiltered.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('BOS211-7919015E-VT450903_2021-12-13_2021-12-13_SIGNAL_GROUP-filtered.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def xml_to_dict(filename):\n",
    "    with open(filename) as t:\n",
    "        data = t.read()\n",
    "        xmldict = xmltodict.parse(data)\n",
    "    return xmldict\n",
    "\n",
    "def lanedata_extract(filename):\n",
    "    #import xml as dict\n",
    "    xmldict = xml_to_dict(filename)\n",
    "\n",
    "    #access the lanesets in the dict\n",
    "    lanesets = xmldict['topology']['mapData']['intersections']['intersectionGeometry']['laneSet']['genericLane']\n",
    "\n",
    "    #extract lane data\n",
    "    lanedata = []\n",
    "    for lane in lanesets: #for every lane in lanesets\n",
    "        for node in lane['nodes']['nodeXY']: #for every node in lane\n",
    "            lat, long = node['node-LatLon']['lat'], node['node-LatLon']['lon'] #extract lat and long\n",
    "            lanedata.append((float(lat) / 10000000, float(long) / 10000000)) #divide so we get the correct values\n",
    "    \n",
    "    lanedf = pd.DataFrame(lanedata)#convert collected data to a dataframe\n",
    "    lanedf.columns = ['lat', 'long'] #set column names\n",
    "    \n",
    "    return lanedf\n",
    "\n",
    "def inductionloop_extract(filename):\n",
    "    #import xml as dict\n",
    "    xmldict = xml_to_dict(filename)\n",
    "    \n",
    "    #access the sensorsets in the dict\n",
    "    sensorsets = xmldict['topology']['controlData']['controller']['controlUnits']['controlUnit']['controlledIntersections']['controlledIntersection']['sensors']['sensor']\n",
    "    \n",
    "    #extract the loop info\n",
    "    loop_data = []\n",
    "    for sensor in sensorsets:\n",
    "        sensor_type = sensor['sensorDeviceType']\n",
    "        if sensor_type == 'inductionLoop': #only extract data if its an inductionLoop\n",
    "            lat, long = sensor['sensorPosition']['lat'], sensor['sensorPosition']['long']\n",
    "            loop_data.append((float(lat) / 10000000, float(long) / 10000000))\n",
    "\n",
    "    sensordf = pd.DataFrame(loop_data)\n",
    "    sensordf.columns = ['lat', 'long']\n",
    "\n",
    "    return sensordf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmappie(filename):\n",
    "    #get both loops and lanes\n",
    "    loops = inductionloop_extract(filename)\n",
    "    lanes = lanedata_extract(filename)\n",
    "    \n",
    "    #plot the points\n",
    "    plt.scatter(x=lanes['long'], y=lanes['lat'])\n",
    "    plt.scatter(x=loops['long'], y=loops['lat'])\n",
    "    plt.show()\n",
    "\n",
    "plotmappie(\"7919015E_BOS211_ITF_COMPLETE.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanedf = lanedata_extract('7919015E_BOS211_ITF_COMPLETE.xml')\n",
    "lat = lanedf.lat\n",
    "long = lanedf.long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = (xml_to_dict('7919015E_BOS211_ITF_COMPLETE.xml')['topology']['mapData']['intersections']['intersectionGeometry']['laneSet']['genericLane'])\n",
    "for x in xml:\n",
    "    \n",
    "    \n",
    "    if x['laneAttributes']['sharedWith'] == '0001000000':\n",
    "        \n",
    "        connect_dict = {}\n",
    "        try:\n",
    "            connect_dict[x['laneID']] = [{'connecting_lane': x['connectsTo']['connection']['connectingLane']['lane'], 'maneuver':x['connectsTo']['connection']['connectingLane']['maneuver']}]\n",
    "        except TypeError:\n",
    "            \n",
    "            temp_list = []\n",
    "            for i in x['connectsTo']['connection']:\n",
    "                temp_list.append({'connecting_lane': i['connectingLane']['lane'], 'maneuver':i['connectingLane']['maneuver']})\n",
    "            connect_dict[x['laneID']] = temp_list\n",
    "        except KeyError:\n",
    "            pass\n",
    "            \n",
    "        print(connect_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(long,lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_lat_long(lat,long, grid_size = 100):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_lat = list([int(abs(round(float(x),len(str(grid_size))-1) * grid_size)) for x in scaler.fit_transform(np.array(lat).reshape(-1,1))])\n",
    "    scaled_long = list([int(abs(round(float(x),len(str(grid_size))-1) * grid_size)) for x in scaler.fit_transform(np.array(long).reshape(-1,1))])\n",
    "    \n",
    "    return list(set(zip(scaled_long,scaled_lat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = scale_lat_long(lat,long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=0).fit_predict(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = inductionloop_extract('7919015E_BOS211_ITF_COMPLETE.xml')\n",
    "x = test.long\n",
    "y = test.lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=15, random_state=0).fit_predict(list(zip(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y, c = kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmldict = xml_to_dict('7919015E_BOS211_ITF_COMPLETE.xml')\n",
    "    \n",
    "sensorsets = xmldict['topology']['controlData']['controller']['controlUnits']['controlUnit']['controlledIntersections']['controlledIntersection']['sensors']['sensor']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sensorsets:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_dict = {x['name']: {'laneID' : x['sensorAllocations']['sensorAllocation']['laneID'], 'lat':x['sensorPosition']['lat'], 'long':x['sensorPosition']['long'], 'length': x['length'], 'distance': x['sensorAllocations']['sensorAllocation']['distance']} for x in sensorsets if x['sensorDeviceType'] == 'inductionLoop' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([x['laneID'] for x in sensor_dict.values()]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laneattributes = xmldict['topology']['mapData']['intersections']['intersectionGeometry']['laneSet']['genericLane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laneattributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_traffic_dict = {x['laneID']:x['laneAttributes']['sharedWith'] for x in laneattributes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sensor_dict:\n",
    "    sensor_dict[k]['sharedWith'] = lane_traffic_dict[sensor_dict[k]['laneID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df = pd.DataFrame(sensor_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_df = s_df[s_df.sharedWith == '0001000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(scale_lat_long(s_df.lat,s_df.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df['lat_conv'] = temp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df['long_conv'] = temp[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(s_df.lat_conv, s_df.long_conv, c = s_df.laneID.astype(int), cmap = plt.get_cmap('prism'))\n",
    "\n",
    "for i, txt in enumerate(s_df.laneID):\n",
    "    ax.annotate(txt, (s_df.lat_conv[i],s_df.long_conv[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.laneID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[float(x) for x in s_df.laneID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(s_df.laneID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmldict = xml_to_dict('7919015E_BOS211_ITF_COMPLETE.xml')\n",
    "\n",
    "lanesets = xmldict['topology']['mapData']['intersections']['intersectionGeometry']['laneSet']['genericLane']\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame([x for x in lanesets if x['laneAttributes']['sharedWith'] == '0001000000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(set(list(set(df.ingressApproach)) + (list(set(df.egressApproach)))))\n",
    "l.remove(np.NaN)\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = []\n",
    "\n",
    "for x in lanesets:\n",
    "    if x['laneAttributes']['sharedWith'] == '0001000000':\n",
    "        \n",
    "        try:\n",
    "            print(x['ingressApproach'])\n",
    "        except:\n",
    "            print(x['egressApproach'])\n",
    "        \n",
    "        test = []\n",
    "        for i in (x['nodes']['nodeXY']):\n",
    "            test.append((float(i['node-LatLon']['lat']),float(i['node-LatLon']['lon'])))\n",
    "        \n",
    "        \n",
    "        coords = np.array(test)\n",
    "        thing = [coords[0],coords[-1]]\n",
    "        reg = LinearRegression().fit(np.array(thing)[:,0].reshape(-1,1),np.array(thing)[:,1].reshape(-1,1))\n",
    "        coefs.append(reg.coef_)\n",
    "\n",
    "print(coefs)\n",
    "print()\n",
    "\n",
    "\n",
    "import math\n",
    "[math.atan(x) for x in coefs]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1,100)\n",
    "for count, i in enumerate(coefs):\n",
    "    \n",
    "    plt.plot(x, coefs[count][0]*x)\n",
    "plt.xlabel('x', color='#1C2833')\n",
    "plt.ylabel('y', color='#1C2833')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "\n",
    "div = 10000000\n",
    "\n",
    "coords_1 = (516841400 , 52933456 )\n",
    "coords_2 = (516831191, 52938160)\n",
    "\n",
    "#print(coords_1,coords_2)\n",
    "\n",
    "#print(geopy.distance.distance(coords_1, coords_2).m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_lat_long(coords_1,coords_2, grid_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(np.array(coords_1).reshape(-1,1),np.array(coords_2).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(scaled_coords[:,0].reshape(-1,1),scaled_coords[:,1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}